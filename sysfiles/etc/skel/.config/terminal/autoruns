#!/bin/bash

# Commands to run automatically
# setxkbmap -layout us -variant intl_nodeadkeys
# xinput set-button-map 'Kensington Expert Mouse' 1 2 3 4 5 6 7 3

# Remove home directories
if [ -d "$HOME/Music" ]; then
    rmdir "$HOME"/Music
fi

if [ -d "$HOME/Public" ]; then
    rmdir "$HOME"/Public
fi

if [ -d /mnt/stash_files/stash_downloads ]; then
    if [ ! -L "$HOME"/Downloads ]; then
        rmdir "$HOME"/Downloads &&
        ln -s /mnt/stash_files/stash_downloads "$HOME"/Downloads
    fi
fi

# Default home directories
mkdir -p "$HOME"/{Appimage,Security,Workbench}
mkdir -p "$HOME"/.gnupg
mkdir -p "$HOME"/.ssh/keys
mkdir -p "$HOME"/.yubico
mkdir -p "$HOME"/.local/share/fonts


# Set persmissions
find "$HOME"/.ssh -type f -exec chmod 600 {} \;
find "$HOME"/.ssh -type d -exec chmod 700 {} \;
find "$HOME"/.gnupg -type f -exec chmod 600 {} \;
find "$HOME"/.gnupg -type d -exec chmod 700 {} \;
find "$HOME"/.yubico -type f -exec chmod 600 {} \;
find "$HOME"/.yubico -type d -exec chmod 700 {} \;

# GNOME Settings
gsettings set org.gnome.desktop.peripherals.touchpad tap-and-drag-lock true

# Mount points
  if [ ! -L "$HOME/Mounts" ]; then
      ln -s /mnt "$HOME"/Mounts 2>/dev/null
  fi
#
# Volatile space
mkdir -p /tmp/Volatile
  if [ ! -f "$HOME/Volatile" ]; then
      ln -s /tmp/Volatile "$HOME" 2>/dev/null
  fi

# Host or Toolbox autoruns
  if [ -f "/run/.toolboxenv" ]; then
    # Toolbox Environment
    echo
  else
    # Host Environment
    echo
    # Install local AI environment
    if ! [[ $(podman start ollama 2>/dev/null) ]]; then
        read -p "Do you want to procees with local AI ollama install? (y/N): " response
        if [ "$response" = "y" ] || [ "$response" = "Y" ]; then
            podman run -d -v ollama:/root/.ollama -p 11434:11434 --restart always --name ollama docker.io/ollama/ollama:latest
            podman exec -it ollama ollama pull llama3.2
            podman run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --restart always --name open-webui ghcr.io/open-webui/open-webui:latest
        fi
    fi

    if ! [[ $(podman start open-webui 2>/dev/null) ]]; then
        read -p "Do you want to procees with local AI open-webui install? (y/N): " response
        if [ "$response" = "y" ] || [ "$response" = "Y" ]; then
            podman run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --restart always --name open-webui ghcr.io/open-webui/open-webui:latest
        fi
    fi
  fi

cd
cls
